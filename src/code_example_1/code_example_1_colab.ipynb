{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ OCR and Text Extraction Workflow\n",
        "\n",
        "This notebook demonstrates a multi-agent system using Upsonic:\n",
        "\n",
        "1. **OCR Agent**: Reads text from an ID card image\n",
        "2. **Extractor Agent**: Extracts specific information (ID Number) from OCR output\n",
        "\n",
        "**Flow**: Image ‚Üí OCR ‚Üí Text Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Installation\n",
        "\n",
        "First, install the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install direct dependencies with exact versions\n",
        "# (transitive dependencies come automatically)\n",
        "!pip install -q upsonic==0.71.5 python-dotenv==1.2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë API Key Setup\n",
        "\n",
        "Enter your OpenAI API key (required for the agents):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai_api_key = getpass('Enter your OpenAI API key: ')\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "print(\"‚úÖ API key configured\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì§ Upload Image\n",
        "\n",
        "Upload an ID card image to analyze (or use the sample image):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Option 1: Upload your own image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "if uploaded:\n",
        "    image_path = list(uploaded.keys())[0]\n",
        "    print(f\"‚úÖ Image uploaded: {image_path}\")\n",
        "    \n",
        "    # Display the image\n",
        "    display(Image(filename=image_path, width=400))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No image uploaded. Please run this cell again and select an image.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from upsonic import Agent, Task"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Define Agents\n",
        "\n",
        "Create two specialized agents:\n",
        "- **OCR Agent**: Expert at reading text from images\n",
        "- **Extractor Agent**: Expert at finding specific information in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OCR Agent: Reads text from images\n",
        "ocr_agent = Agent(\n",
        "    name=\"OCR Agent\",\n",
        "    role=\"Text Recognition Specialist\",\n",
        "    goal=\"Extract all visible text from images accurately\",\n",
        "    instructions=\"\"\"You are an expert OCR (Optical Character Recognition) specialist.\n",
        "    Your job is to carefully read images and extract all visible text with high accuracy.\n",
        "    You pay attention to every detail and return complete text content.\"\"\",\n",
        "    model=\"openai/gpt-4o\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ OCR Agent created\")\n",
        "\n",
        "# Extractor Agent: Finds specific information\n",
        "extractor_agent = Agent(\n",
        "    name=\"Extractor Agent\",\n",
        "    role=\"Information Extraction Specialist\",\n",
        "    goal=\"Find and extract specific information from text\",\n",
        "    instructions=\"\"\"You are a data extraction expert. You excel at finding specific\n",
        "    information in text documents. You are precise and always return exactly\n",
        "    what is requested, nothing more, nothing less.\"\"\",\n",
        "    model=\"openai/gpt-4o\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Extractor Agent created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Define Tasks\n",
        "\n",
        "Create tasks for each agent:\n",
        "1. **OCR Task**: Read all text from the image\n",
        "2. **Extraction Task**: Find the ID Number from OCR output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Task 1: OCR - Read text from image\n",
        "ocr_task = Task(\n",
        "    description=\"\"\"Read the ID card image and extract ALL visible text.\n",
        "    \n",
        "    Return all text you can see in the image, maintaining the original structure.\n",
        "    Include all fields and their values.\"\"\",\n",
        "    context=[image_path]  # Image file path in context\n",
        ")\n",
        "\n",
        "print(\"‚úÖ OCR Task created\")\n",
        "\n",
        "# Task 2: Extract ID Number\n",
        "extraction_task = Task(\n",
        "    description=\"\"\"From the OCR text provided in the context, find and extract\n",
        "    ONLY the ID Number value.\n",
        "    \n",
        "    Look for a field labeled 'ID Number' and return only the number itself.\n",
        "    If you find it, return just the number. If not found, return 'NOT_FOUND'.\"\"\",\n",
        "    context=[ocr_task]  # This task depends on ocr_task output\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Extraction Task created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ñ∂Ô∏è Execute Workflow\n",
        "\n",
        "Run the multi-agent workflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"OCR AND TEXT EXTRACTION WORKFLOW\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: OCR - Reading image\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 1: OCR - Reading image\")\n",
        "print(\"=\" * 70)\n",
        "ocr_result = ocr_agent.print_do(ocr_task)\n",
        "print(f\"\\nüìÑ OCR Output:\")\n",
        "print(ocr_result)\n",
        "print(f\"\\nüìä Characters read: {len(str(ocr_result))}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: EXTRACTION - Finding ID Number\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 2: EXTRACTION - Finding ID Number\")\n",
        "print(\"=\" * 70)\n",
        "extraction_result = extractor_agent.print_do(extraction_task)\n",
        "print(f\"\\nüîç Extracted ID Number: {extraction_result}\")\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"WORKFLOW COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n‚úÖ OCR Agent read {len(str(ocr_result))} characters\")\n",
        "print(f\"‚úÖ Extractor Agent extracted: {extraction_result}\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Results\n",
        "\n",
        "The workflow demonstrates:\n",
        "- **Agent collaboration**: OCR Agent output becomes input for Extractor Agent\n",
        "- **Task chaining**: Tasks can depend on each other via `context`\n",
        "- **Specialized roles**: Each agent focuses on what it does best\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ Try It Yourself\n",
        "\n",
        "1. Upload a different ID card image\n",
        "2. Modify the extraction task to find different fields (Name, Date of Birth, etc.)\n",
        "3. Add more agents to the workflow\n",
        "\n",
        "### üìö Learn More\n",
        "\n",
        "- [Upsonic Documentation](https://docs.upsonic.co)\n",
        "- [GitHub Repository](https://github.com/Upsonic/Upsonic)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}